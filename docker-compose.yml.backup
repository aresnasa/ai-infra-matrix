services:
  # PostgreSQL 数据库服务（主要用于门户与Gitea等组件）
  postgres:
    image: postgres:15-alpine
    container_name: ai-infra-postgres
    env_file:
      - .env
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-ai-infra-matrix}
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      TZ: Asia/Shanghai
    expose:
      - "5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - ai-infra-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-postgres} -d ${POSTGRES_DB:-ai-infra-matrix}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    restart: unless-stopped

  # OceanBase 社区版（单机）
  # 参考: https://www.oceanbase.com/docs/community-observer-cn-10000000001878977
  oceanbase:
    image: oceanbase/oceanbase-ce:4.3.5-lts
    container_name: ai-infra-oceanbase
    environment:
      TZ: Asia/Shanghai
    # 对外映射 2881 端口，供客户端连接（obclient, JDBC等）
    ports:
      - "2881:2881"
    expose:
      - "2881"
    # 初始化SQL脚本目录，容器启动时会自动执行 /root/boot/init.d 下的 *.sql / *.sh
    # 可通过 OCEANBASE_INIT_DIR 指定宿主机路径（默认 ./data/oceanbase/init.d）
    volumes:
      - ${OCEANBASE_INIT_DIR:-./data/oceanbase/init.d}:/root/boot/init.d:ro
    networks:
      - ai-infra-network
    healthcheck:
      # OceanBase 健康检查：分阶段检查
      # 1. 检查 observer 进程是否运行
      # 2. 检查端口是否监听
      # 3. 尝试数据库连接（可选，因为初始化可能较慢）
      test:
        - "CMD-SHELL"
        - |
          # 检查 observer 进程
          if ! pgrep -f observer >/dev/null 2>&1; then
            echo "OceanBase observer process not running" && exit 1
          fi
          # 检查端口监听（使用 ss 或 netstat 替代 nc）
          if command -v ss >/dev/null 2>&1; then
            ss -tln | grep :2881 >/dev/null 2>&1 || (echo "Port 2881 not listening" && exit 1)
          elif command -v netstat >/dev/null 2>&1; then
            netstat -tln | grep :2881 >/dev/null 2>&1 || (echo "Port 2881 not listening" && exit 1)
          else
            echo "Port check skipped (no ss/netstat available)"
          fi
          # 如果一切正常，返回成功
          echo "OceanBase health check passed"
      interval: 30s
      timeout: 15s
      retries: 10
      start_period: 120s
    restart: unless-stopped

  # MySQL 数据库服务 (用于SLURM)
  mysql:
    image: mysql:8.0
    container_name: ai-infra-mysql
    environment:
      TZ: Asia/Shanghai
      MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASSWORD:-mysql123}
      MYSQL_DATABASE: ${SLURM_DB_NAME:-slurm_acct_db}
      MYSQL_USER: ${SLURM_DB_USER:-slurm}
      MYSQL_PASSWORD: ${SLURM_DB_PASSWORD:-slurm123}
    expose:
      - "3306"
    ports:
      - "3306:3306"
    volumes:
      - mysql_data:/var/lib/mysql
    networks:
      - ai-infra-network
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost", "-u", "root", "-p${MYSQL_ROOT_PASSWORD:-mysql123}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    restart: unless-stopped

# Redis 缓存服务
  redis:
    image: redis:7-alpine
    container_name: ai-infra-redis
    env_file:
      - .env
    # Defer expansion of REDIS_PASSWORD to the container environment
    command: ["sh", "-c", "exec redis-server --requirepass \"$${REDIS_PASSWORD}\""]
    expose:
      - "6379"
    volumes:
      - redis_data:/data
    networks:
      - ai-infra-network
    environment:
      TZ: Asia/Shanghai
    healthcheck:
      test: ["CMD-SHELL", "redis-cli -a \"$${REDIS_PASSWORD}\" ping || exit 1"]
      interval: 10s
      timeout: 3s
      retries: 5
      start_period: 10s
    restart: unless-stopped

# Kafka 消息队列服务 (KRaft模式，无需Zookeeper)
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: ai-infra-kafka
    environment:
      # KRaft 模式配置
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:9094
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093,PLAINTEXT_HOST://0.0.0.0:9094
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      
      # 集群和主题配置
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_NUM_PARTITIONS: 3
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1
      
      # 日志和存储配置
      KAFKA_LOG_RETENTION_HOURS: 168  # 7天
      KAFKA_LOG_SEGMENT_BYTES: 1073741824  # 1GB
      KAFKA_LOG_RETENTION_BYTES: 10737418240  # 10GB
      KAFKA_LOG_DIRS: /var/lib/kafka/data
      
      # 性能优化
      KAFKA_SOCKET_SEND_BUFFER_BYTES: 102400
      KAFKA_SOCKET_RECEIVE_BUFFER_BYTES: 102400
      KAFKA_SOCKET_REQUEST_MAX_BYTES: 104857600
      KAFKA_NUM_NETWORK_THREADS: 8
      KAFKA_NUM_IO_THREADS: 8
      KAFKA_BACKGROUND_THREADS: 10
      
      # 集群元数据配置（KRaft）
      CLUSTER_ID: 'gYf__u4_TgSoREBUnP-YzQ'
      
      TZ: Asia/Shanghai
    expose:
      - "9092"
      - "9093"
    ports:
      - "9094:9094"  # 外部访问端口
    volumes:
      - kafka_data:/var/lib/kafka/data
      - kafka_logs:/var/log/kafka
    networks:
      - ai-infra-network
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: unless-stopped

# Kafka UI 管理界面
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: ai-infra-kafka-ui
    depends_on:
      kafka:
        condition: service_healthy
    volumes:
      - ./config/kafka-ui-config.yml:/etc/kafka-ui/dynamic_config.yml
    environment:
      DYNAMIC_CONFIG_ENABLED: 'true'
      TZ: Asia/Shanghai
    expose:
      - "8080"
    ports:
      - "9095:8080"  # Kafka UI 管理界面
    networks:
      - ai-infra-network
    restart: unless-stopped

  # OpenLDAP 目录服务
  openldap:
    image: osixia/openldap:stable
    container_name: ai-infra-openldap
    env_file:
      - .env
    environment:
      LDAP_ORGANISATION: "${LDAP_ORGANISATION:-AI Infrastructure}"
      LDAP_DOMAIN: "${LDAP_DOMAIN:-ai-infra.com}"
      LDAP_ADMIN_PASSWORD: "${LDAP_ADMIN_PASSWORD}"
      LDAP_CONFIG_PASSWORD: "${LDAP_CONFIG_PASSWORD}"
      LDAP_BASE_DN: "${LDAP_BASE_DN:-dc=ai-infra,dc=com}"
      TZ: "${TZ:-Asia/Shanghai}"
    expose:
      - "389"
      - "636"
    volumes:
      - ldap_data:/var/lib/ldap
      - ldap_config:/etc/ldap/slapd.d
    networks:
      - ai-infra-network
    healthcheck:
      test: ["CMD", "sh", "-c", "ldapsearch -x -H ldap://localhost -b dc=ai-infra,dc=com -D cn=admin,dc=ai-infra,dc=com -w \"$$LDAP_ADMIN_PASSWORD\""]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    restart: unless-stopped

  # phpLDAPadmin Web界面
  phpldapadmin:
    image: osixia/phpldapadmin:stable
    container_name: ai-infra-phpldapadmin
    environment:
      PHPLDAPADMIN_LDAP_HOSTS: "${LDAP_HOST:-openldap}"
      PHPLDAPADMIN_HTTPS: "${PHPLDAPADMIN_HTTPS:-false}"
      TZ: "${TZ:-Asia/Shanghai}"
    expose:
      - "80"
    depends_on:
      openldap:
        condition: service_healthy
    networks:
      - ai-infra-network
    restart: unless-stopped

  # 后端初始化服务 - 创建admin用户和基础数据
  backend-init:
    image: crpi-jl2i63tqhvx30nje.cn-chengdu.personal.cr.aliyuncs.com/ai-infra-matrix/ai-infra-backend-init:v0.3.8
    build:
      context: ./src/backend
      dockerfile: Dockerfile
      target: backend-init
      args:
        VERSION: ${IMAGE_TAG:-v0.3.8}
    container_name: ai-infra-backend-init
    env_file:
      - .env
    environment:
      # 默认仍支持 Postgres（未启用 OceanBase 时）
      - DB_HOST=${POSTGRES_HOST:-postgres}
      - DB_PORT=${POSTGRES_PORT:-5432}
      - DB_USER=${POSTGRES_USER:-postgres}
      - DB_PASSWORD=${POSTGRES_PASSWORD:-postgres}
      - DB_NAME=${POSTGRES_DB:-ai-infra-matrix}
      # OceanBase（可选）
      - OB_ENABLED=${OB_ENABLED:-false}
      - OB_HOST=${OB_HOST:-oceanbase}
      - OB_PORT=${OB_PORT:-2881}
      - OB_USER=${OB_USER:-root@sys}
      - OB_PASSWORD=${OB_PASSWORD:-}
      - OB_DB=${OB_DB:-aimatrix}
      - OB_PARAMS=${OB_PARAMS:-charset=utf8mb4&parseTime=True&loc=Local}
      - REDIS_HOST=${REDIS_HOST:-redis}
      - REDIS_PORT=${REDIS_PORT:-6379}
      - REDIS_PASSWORD=${REDIS_PASSWORD}
      - LDAP_SERVER=${LDAP_HOST:-openldap}
      - LDAP_PORT=${LDAP_PORT:-389}
      - LOG_LEVEL=${LOG_LEVEL:-info}
      - TZ=Asia/Shanghai
    command: ["./init"]
    depends_on:
      oceanbase:
        condition: service_healthy
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      openldap:
        condition: service_healthy
    networks:
      - ai-infra-network
    restart: "no"

  # 后端 API 服务
  backend:
    image: crpi-jl2i63tqhvx30nje.cn-chengdu.personal.cr.aliyuncs.com/ai-infra-matrix/ai-infra-backend:v0.3.8
    build:
      context: ./src/backend
      dockerfile: Dockerfile
      target: backend
      args:
        VERSION: ${IMAGE_TAG:-v0.3.8}
    container_name: ai-infra-backend
    env_file:
      - .env
    environment:
      # 默认仍支持 Postgres
      DB_HOST: "${POSTGRES_HOST:-postgres}"
      DB_PORT: "${POSTGRES_PORT:-5432}"
      DB_USER: "${POSTGRES_USER:-postgres}"
      DB_PASSWORD: "${POSTGRES_PASSWORD:-postgres}"
      DB_NAME: "${POSTGRES_DB:-ai-infra-matrix}"
      # 开启 OceanBase 将覆盖上面的连接，后端将优先使用 OceanBase
      OB_ENABLED: "${OB_ENABLED:-false}"
      OB_HOST: "${OB_HOST:-oceanbase}"
      OB_PORT: "${OB_PORT:-2881}"
      OB_USER: "${OB_USER:-root@sys}"
      OB_PASSWORD: "${OB_PASSWORD:-}"
      OB_DB: "${OB_DB:-aimatrix}"
      OB_PARAMS: "${OB_PARAMS:-charset=utf8mb4&parseTime=True&loc=Local}"
      REDIS_HOST: "${REDIS_HOST:-redis}"
      REDIS_PORT: "${REDIS_PORT:-6379}"
      REDIS_PASSWORD: "${REDIS_PASSWORD}"
      LDAP_SERVER: "${LDAP_HOST:-openldap}"
      LDAP_PORT: "${LDAP_PORT:-389}"
      LDAP_BASE_DN: "${LDAP_BASE_DN:-dc=example,dc=org}"
      # SLURM Master SSH 配置（用于缩容等操作）
      SLURM_MASTER_HOST: "${SLURM_MASTER_HOST:-slurm-master}"
      SLURM_MASTER_PORT: "${SLURM_MASTER_PORT:-22}"
      SLURM_MASTER_USER: "${SLURM_MASTER_USER:-root}"
      SLURM_MASTER_PASSWORD: "${SLURM_MASTER_PASSWORD}"
      # SaltStack 配置
      SALTSTACK_ENABLED: "${SALTSTACK_ENABLED:-true}"
      SALTSTACK_MASTER_HOST: "${SALTSTACK_MASTER_HOST:-saltstack}"
      SALTSTACK_MASTER_URL: "${SALTSTACK_MASTER_URL:-}"
      SALT_API_SCHEME: "${SALT_API_SCHEME:-http}"
      SALT_MASTER_HOST: "${SALT_MASTER_HOST:-saltstack}"
      SALT_API_PORT: "${SALT_API_PORT:-8002}"
      SALT_API_USERNAME: "${SALT_API_USERNAME:-saltapi}"
      SALT_API_PASSWORD: "${SALT_API_PASSWORD:-aiinfra-salt}"
      SALT_API_EAUTH: "${SALT_API_EAUTH:-file}"
      SALT_API_TIMEOUT: "${SALT_API_TIMEOUT:-65s}"
      GITEA_ENABLED: "${GITEA_ENABLED:-true}"
      GITEA_BASE_URL: "${GITEA_BASE_URL:-http://gitea:3000}"
      GITEA_ADMIN_TOKEN: "${GITEA_ADMIN_TOKEN}"
      GITEA_AUTO_CREATE: "${GITEA_AUTO_CREATE:-true}"
      GITEA_AUTO_UPDATE: "${GITEA_AUTO_UPDATE:-true}"
      GITEA_SYNC_ENABLED: "${GITEA_SYNC_ENABLED:-true}"
      GITEA_SYNC_INTERVAL_SECONDS: "${GITEA_SYNC_INTERVAL_SECONDS:-600}"
      # Map reserved username 'admin' to a real admin account in Gitea (use 'admin' as default)
      GITEA_ALIAS_ADMIN_TO: "${GITEA_ALIAS_ADMIN_TO:-admin}"
      # E2E 测试配置（开发/测试环境）
      E2E_ALLOW_FAKE_LDAP: "${E2E_ALLOW_FAKE_LDAP:-true}"
      LOG_LEVEL: "${LOG_LEVEL:-info}"
      TZ: "Asia/Shanghai"
    expose:
      - "8082"
    ports:
      # Debug: expose internal 8082 on host for direct backend access (bypass Nginx)
      - "${EXTERNAL_HOST}:${BACKEND_DEBUG_PORT:-8082}:8082"
    extra_hosts:
      - "kubernetes.docker.internal:host-gateway"
      - "host.docker.internal:host-gateway"
    depends_on:
      oceanbase:
        condition: service_healthy
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      openldap:
        condition: service_healthy
      backend-init:
        condition: service_completed_successfully
    volumes:
      - ./src/backend/outputs:/app/outputs
      - ./src/backend/uploads:/app/uploads
    networks:
      - ai-infra-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8082/api/health"]
      interval: 30s
      timeout: 15s
      retries: 5
      start_period: 60s
    restart: unless-stopped

  # 前端应用服务
  frontend:
    image: crpi-jl2i63tqhvx30nje.cn-chengdu.personal.cr.aliyuncs.com/ai-infra-matrix/ai-infra-frontend:v0.3.8
    build:
      context: ./src/frontend
      dockerfile: Dockerfile
      args:
        REACT_APP_API_URL: /api
        REACT_APP_JUPYTERHUB_URL: /jupyter
        VERSION: ${IMAGE_TAG:-v0.3.8}
    container_name: ai-infra-frontend
    environment:
      TZ: Asia/Shanghai
    expose:
      - "80"
    depends_on:
      backend:
        condition: service_healthy
    networks:
      - ai-infra-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    restart: unless-stopped

  # JupyterHub 统一认证服务
  jupyterhub:
    image: crpi-jl2i63tqhvx30nje.cn-chengdu.personal.cr.aliyuncs.com/ai-infra-matrix/ai-infra-jupyterhub:v0.3.8
    env_file:
      - .env
    build:
      context: ./src/jupyterhub
      dockerfile: Dockerfile
      args:
        BUILDKIT_INLINE_CACHE: "${BUILDKIT_INLINE_CACHE:-1}"
        VERSION: ${IMAGE_TAG:-v0.3.8}
    container_name: ai-infra-jupyterhub
    environment:
      - POSTGRES_HOST=${POSTGRES_HOST:-postgres}
      - POSTGRES_PORT=${POSTGRES_PORT:-5432}
      - POSTGRES_DB=jupyterhub_db
      - POSTGRES_USER=${POSTGRES_USER:-postgres}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-postgres}
      - DB_HOST=${POSTGRES_HOST:-postgres}
      - DB_PORT=${POSTGRES_PORT:-5432}
      - DB_NAME=jupyterhub_db
      - DB_USER=${POSTGRES_USER:-postgres}
      - DB_PASSWORD=${POSTGRES_PASSWORD:-postgres}
      - REDIS_HOST=${REDIS_HOST:-redis}
      - REDIS_PORT=${REDIS_PORT:-6379}
      - REDIS_DB=1
      - REDIS_PASSWORD=${REDIS_PASSWORD}
      - JWT_SECRET=${JWT_SECRET}
      - JUPYTERHUB_ADMIN_USERS=admin,jupyter-admin
      - CONFIGPROXY_AUTH_TOKEN=${CONFIGPROXY_AUTH_TOKEN}
      - JUPYTERHUB_CRYPT_KEY=${JUPYTERHUB_CRYPT_KEY:-a3d7c9e5b1f2048c7d9e3b6a5c1f08e2a7b3c9d5e1f2048c7d9e3b6a5c1f08e2}
      - SESSION_TIMEOUT=86400
      - USE_CUSTOM_AUTH=true
      - AI_INFRA_BACKEND_URL=${BACKEND_URL:-http://backend:8082}
      - AI_INFRA_API_TOKEN=ai-infra-hub-token
      - JUPYTERHUB_AUTO_LOGIN=true
      - JUPYTERHUB_DEV_MODE=true
      - JUPYTERHUB_IMAGE=ai-infra-singleuser:${IMAGE_TAG:-v0.3.8}
      - JUPYTERHUB_NETWORK=ai-infra-network
      - JUPYTERHUB_MEM_LIMIT=3G
      - JUPYTERHUB_CPU_LIMIT=1.0
      - JUPYTERHUB_IDLE_CULLER_ENABLED=true
      - JUPYTERHUB_IDLE_TIMEOUT=3600
      - JUPYTERHUB_CULL_TIMEOUT=7200
      - JUPYTERHUB_DEBUG=false
      - JUPYTERHUB_LOG_LEVEL=INFO
      - JUPYTERHUB_ACCESS_LOG=true
      - JUPYTERHUB_USE_PROXY=true
      - JUPYTERHUB_PUBLIC_HOST=${JUPYTERHUB_PUBLIC_HOST}
      - JUPYTERHUB_CORS_ORIGIN=${JUPYTERHUB_CORS_ORIGIN}
      - TZ=Asia/Shanghai
    ports:
      - "${EXTERNAL_HOST}:${JUPYTERHUB_EXTERNAL_PORT}:8000"
    expose:
      - "8000"
      - "8091"
    volumes:
      - jupyterhub_data:/srv/data/jupyterhub
      - jupyterhub_notebooks:/srv/jupyterhub/notebooks
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - ./shared:/srv/jupyterhub/shared:rw
      - ./src/jupyterhub/jupyterhub_config.py:/srv/jupyterhub/jupyterhub_config.py:ro
      - ./src/jupyterhub/backend_integrated_config.py:/srv/jupyterhub/backend_integrated_config.py:ro
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      backend:
        condition: service_healthy
    networks:
      - ai-infra-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/jupyter/hub/api"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    restart: unless-stopped

  # 单用户镜像构建器（不运行，仅用于构建镜像供Spawner使用）
  singleuser-builder:
    image: crpi-jl2i63tqhvx30nje.cn-chengdu.personal.cr.aliyuncs.com/ai-infra-matrix/ai-infra-singleuser:v0.3.8
    build:
      context: ./src/singleuser
      dockerfile: Dockerfile
      args:
        VERSION: ${IMAGE_TAG:-v0.3.8}
    command: ["true"]
    networks:
      - ai-infra-network
    restart: "no"

# SaltStack 配置管理服务
  saltstack:
    image: crpi-jl2i63tqhvx30nje.cn-chengdu.personal.cr.aliyuncs.com/ai-infra-matrix/ai-infra-saltstack:v0.3.8
    build:
      context: ./src/saltstack
      dockerfile: Dockerfile
      args:
        VERSION: ${IMAGE_TAG:-v0.3.8}
    container_name: ai-infra-saltstack
    privileged: true
    security_opt:
      - seccomp:unconfined
    tmpfs:
      - /run
      - /run/lock
    env_file:
      - .env
    environment:
      - TZ=Asia/Shanghai
      # Suppress upstream deprecation warnings to keep logs clean
      - PYTHONWARNINGS=ignore::DeprecationWarning
      - SALT_MASTER_HOST=saltstack
      - AI_INFRA_BACKEND_URL=${BACKEND_URL:-http://backend:8082}
      - DEBUG_MODE=${DEBUG_MODE:-false}
      - SALT_API_USERNAME=${SALT_API_USERNAME:-saltapi}
      - SALT_API_PASSWORD=${SALT_API_PASSWORD:-aiinfra-salt}
    expose:
      - "4505"  # Salt Master Publish Port
      - "4506"  # Salt Master Return Port
      - "8002"  # Salt API Port
    volumes:
      - /sys/fs/cgroup:/sys/fs/cgroup:rw
      - salt_data:/var/cache/salt
      - salt_logs:/var/log/salt
      - salt_keys:/etc/salt/pki
    networks:
      - ai-infra-network
    depends_on:
      backend:
        condition: service_healthy
      postgres:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "sh", "-c", "nc -z 127.0.0.1 4506 && nc -z 127.0.0.1 8002"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    restart: unless-stopped

    # SLURM Master 服务
  slurm-master:
    image: ai-infra-slurm-master:${IMAGE_TAG:-v0.3.8}
    build:
      context: ./src/slurm-master
      dockerfile: Dockerfile
      args:
        VERSION: ${IMAGE_TAG:-v0.3.8}
        APPHUB_URL: http://${EXTERNAL_HOST}:${APPHUB_PORT:-8090}
    container_name: ai-infra-slurm-master
    hostname: slurm-master
    privileged: true
    security_opt:
      - seccomp:unconfined
    tmpfs:
      - /run
      - /run/lock
    env_file:
      - .env
    environment:
      - TZ=Asia/Shanghai
      # SLURM 集群配置
      - SLURM_CLUSTER_NAME=${SLURM_CLUSTER_NAME:-ai-infra-cluster}
      - SLURM_CONTROL_MACHINE=${SLURM_CONTROLLER_HOST:-slurm-master}
      - SLURM_CONTROLLER_PORT=${SLURM_CONTROLLER_PORT:-6817}
      - SLURM_SLURMDBD_HOST=${SLURM_SLURMDBD_HOST:-slurm-master}
      - SLURM_SLURMDBD_PORT=${SLURM_SLURMDBD_PORT:-6819}
      # SLURM 数据库配置
      - SLURM_DB_HOST=${SLURM_DB_HOST:-mysql}
      - SLURM_DB_PORT=${SLURM_DB_PORT:-3306}
      - SLURM_DB_NAME=${SLURM_DB_NAME:-slurm_acct_db}
      - SLURM_DB_USER=${SLURM_DB_USER:-slurm}
      - SLURM_DB_PASSWORD=${SLURM_DB_PASSWORD:-slurm123}
      # SLURM 认证配置
      - SLURM_AUTH_TYPE=${SLURM_AUTH_TYPE:-auth/munge}
      - SLURM_MUNGE_KEY=${SLURM_MUNGE_KEY:-ai-infra-slurm-munge-key-dev}
      # SLURM 集群节点配置
      - SLURM_PARTITION_NAME=${SLURM_PARTITION_NAME:-compute}
      - SLURM_DEFAULT_PARTITION=${SLURM_DEFAULT_PARTITION:-compute}
      - SLURM_NODE_PREFIX=${SLURM_NODE_PREFIX:-compute}
      - SLURM_NODE_COUNT=${SLURM_NODE_COUNT:-3}
      # SLURM 测试节点配置
      - SLURM_TEST_NODES=${SLURM_TEST_NODES:-}
      - SLURM_TEST_NODE_CPUS=${SLURM_TEST_NODE_CPUS:-4}
      - SLURM_TEST_NODE_MEMORY=${SLURM_TEST_NODE_MEMORY:-8192}
      # SLURM 作业配置
      - SLURM_MAX_JOB_COUNT=${SLURM_MAX_JOB_COUNT:-10000}
      - SLURM_MAX_ARRAY_SIZE=${SLURM_MAX_ARRAY_SIZE:-1000}
      - SLURM_DEFAULT_TIME_LIMIT=${SLURM_DEFAULT_TIME_LIMIT:-01:00:00}
      - SLURM_MAX_TIME_LIMIT=${SLURM_MAX_TIME_LIMIT:-24:00:00}
      # 后端服务连接
      - AI_INFRA_BACKEND_URL=${BACKEND_URL:-http://backend:8082}
      - DEBUG_MODE=${DEBUG_MODE:-false}
    expose:
      - "6817"  # SLURM Controller
      - "6818"  # SLURM Database Daemon
    ports:
      - "6817:6817"  # SLURM Controller 外部访问
      - "6818:6818"  # SLURM Database Daemon 外部访问
    volumes:
      - /sys/fs/cgroup:/sys/fs/cgroup:rw
      - slurm_master_data:/var/lib/slurm
      - slurm_master_logs:/var/log/slurm
      - slurm_master_spool:/var/spool/slurm
      - slurm_munge_data:/var/lib/munge
      - ./shared:/srv/shared:rw
    depends_on:
      mysql:
        condition: service_healthy
      backend:
        condition: service_healthy
      backend-init:
        condition: service_completed_successfully
    networks:
      - ai-infra-network
    healthcheck:
      test: ["CMD", "/usr/local/bin/healthcheck.sh"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 90s
    restart: unless-stopped

  # Nginx 反向代理服务 - 自定义镜像版本
  nginx:
    image: crpi-jl2i63tqhvx30nje.cn-chengdu.personal.cr.aliyuncs.com/ai-infra-matrix/ai-infra-nginx:v0.3.8
    build:
      context: .
      dockerfile: src/nginx/Dockerfile
      args:
        DEBUG_MODE: ${DEBUG_MODE:-false}
        BUILD_ENV: ${BUILD_ENV:-production}
        VERSION: ${IMAGE_TAG:-v0.3.8}
    container_name: ai-infra-nginx
    ports:
      - "${EXTERNAL_HOST}:${EXTERNAL_PORT}:80"
      - "${EXTERNAL_HOST}:${HTTPS_PORT:-8443}:443"
      - "${EXTERNAL_HOST}:${DEBUG_PORT}:8001"
    volumes:
      - nginx_logs:/var/log/nginx
    env_file:
      - .env
    environment:
      - DEBUG_MODE=${DEBUG_MODE:-false}
      - BUILD_ENV=${BUILD_ENV:-production}
      - BACKEND_HOST=${BACKEND_HOST:-backend}
      - BACKEND_PORT=${BACKEND_PORT:-8082}
      - FRONTEND_HOST=${FRONTEND_HOST:-frontend}
      - FRONTEND_PORT=${FRONTEND_PORT:-80}
      - JUPYTERHUB_HOST=${JUPYTERHUB_HOST:-jupyterhub}
      - JUPYTERHUB_PORT=${JUPYTERHUB_PORT:-8000}
      - TZ=Asia/Shanghai
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      openldap:
        condition: service_healthy
      minio:
        condition: service_healthy
      gitea:
        condition: service_healthy
      frontend:
        condition: service_healthy
      backend:
        condition: service_healthy
      jupyterhub:
        condition: service_healthy
      saltstack:
        condition: service_healthy
      slurm-master:
        condition: service_healthy
    networks:
      - ai-infra-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/health"]
      interval: 30s
      timeout: 15s
      retries: 5
      start_period: 90s
    restart: unless-stopped

  # Kubernetes 代理服务 (可选)
  k8s-proxy:
    image: tecnativa/tcp-proxy
    platform: linux/amd64  # ARM Mac 兼容性配置
    container_name: ai-infra-k8s-proxy
    environment:
      LISTEN: "${K8S_PROXY_LISTEN:-0.0.0.0:6443}"
      TALK: "${K8S_PROXY_TALK:-host.docker.internal:6443}"
      PRE_RESOLVE: "${K8S_PROXY_PRE_RESOLVE:-0}"
      VERBOSE: "${K8S_PROXY_VERBOSE:-1}"
      TZ: "${TZ:-Asia/Shanghai}"
    expose:
      - "6443"
    extra_hosts:
      - "kubernetes.docker.internal:host-gateway"
      - "host.docker.internal:host-gateway"
    networks:
      - ai-infra-network
    restart: unless-stopped

  # Redis 监控界面 (可选)
  redis-insight:
    image: redislabs/redisinsight:latest
    container_name: ai-infra-redis-insight
    environment:
      TZ: Asia/Shanghai
    expose:
      - "8001"
    depends_on:
      - redis
    networks:
      - ai-infra-network
    restart: unless-stopped


  # Gitea 代码托管服务（可选，供门户内嵌）
  gitea:
    image: crpi-jl2i63tqhvx30nje.cn-chengdu.personal.cr.aliyuncs.com/ai-infra-matrix/ai-infra-gitea:v0.3.8
    build:
      context: ./src/gitea
      dockerfile: Dockerfile
    container_name: ai-infra-gitea
    env_file:
      - .env
    environment:
      USER_UID: "${USER_UID:-1000}"
      USER_GID: "${USER_GID:-1000}"
      ROOT_URL: "${ROOT_URL}"
      SUBURL: "${SUBURL:-/gitea}"
      STATIC_URL_PREFIX: "${STATIC_URL_PREFIX:-/gitea}"
      GITEA__server__ROOT_URL: "${ROOT_URL}"
      GITEA__server__SUBURL: "${SUBURL:-/gitea}"
      DOMAIN: "${DOMAIN}"
      PROTOCOL: "${GITEA_PROTOCOL:-http}"
      HTTP_PORT: "${GITEA_HTTP_PORT:-3000}"
      GITEA_DB_TYPE: "${GITEA_DB_TYPE:-postgres}"
      GITEA_DB_HOST: "${GITEA_DB_HOST:-postgres:5432}"
      GITEA_DB_NAME: "${GITEA_DB_NAME:-gitea}"
      # 注意：以下两行必须使用6个空格缩进，保持与其他 environment 项对齐，否则会导致 YAML 解析错误。
      GITEA_DB_USER: "${GITEA_DB_USER:-gitea}"
      GITEA_DB_PASSWD: "${GITEA_DB_PASSWD:-gitea-password}"
      POSTGRES_USER: "${POSTGRES_USER:-postgres}"
      POSTGRES_PASSWORD: "${POSTGRES_PASSWORD:-postgres}"
      DISABLE_REGISTRATION: "${DISABLE_REGISTRATION:-false}"
      REVERSE_PROXY_TRUSTED_PROXIES: "${REVERSE_PROXY_TRUSTED_PROXIES:-0.0.0.0/0,::/0}"
      GITEA__auth__REVERSE_PROXY_AUTHENTICATION_USER: "X-WEBAUTH-USER"
      GITEA__auth__REVERSE_PROXY_AUTHENTICATION_EMAIL: "X-WEBAUTH-EMAIL"
      GITEA__auth__REVERSE_PROXY_AUTHENTICATION_FULL_NAME: "X-WEBAUTH-FULLNAME"
      GITEA__auth__PROXY_ENABLED: "true"
      GITEA__auth__PROXY_HEADER_NAME: "X-WEBAUTH-USER"
      GITEA__auth__PROXY_EMAIL_HEADER: "X-WEBAUTH-EMAIL"
      GITEA__auth__PROXY_FULL_NAME_HEADER: "X-WEBAUTH-FULLNAME"
      GITEA__security__REVERSE_PROXY_LIMIT: "1"
      GITEA__security__REVERSE_PROXY_TRUSTED_PROXIES: "0.0.0.0/0,::/0"
      # Set initial admin identity to 'admin' user
      INITIAL_ADMIN_USERNAME: "${GITEA_ALIAS_ADMIN_TO:-admin}"
      # Admin bootstrap via reverse-proxy SSO only; admin user will be default admin
      GITEA__storage__STORAGE_TYPE: "${GITEA_STORAGE:-local}"
      DATA_PATH: "${GITEA_DATA_PATH:-/data/gitea}"
      MINIO_ENDPOINT: "${MINIO_HOST:-minio}:${MINIO_PORT:-9000}"
      MINIO_BUCKET: "${MINIO_BUCKET_GITEA:-gitea}"
      MINIO_USE_SSL: "${MINIO_USE_SSL:-false}"
      MINIO_LOCATION: "${MINIO_REGION:-us-east-1}"
      MINIO_ACCESS_KEY: "${MINIO_ACCESS_KEY:-minioadmin}"
      MINIO_SECRET_KEY: "${MINIO_SECRET_KEY:-minioadmin}"
      TZ: "${TZ:-Asia/Shanghai}"
    expose:
      - "3000"
      - "22"
    ports:
      # Debug: expose internal 3000 on host for direct backend access (bypass Nginx)
      - "${EXTERNAL_HOST}:${GITEA_EXTERNAL_PORT}:3000"
    volumes:
      - gitea_data:/data
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      openldap:
        condition: service_healthy
    networks:
      - ai-infra-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/"]
      interval: 30s
      timeout: 15s
      retries: 5
      start_period: 60s
    restart: unless-stopped

  # MinIO (S3-compatible)
  minio:
    image: minio/minio:latest
    container_name: ai-infra-minio
    command: server /data --console-address ":9001"
    env_file:
      - .env
    environment:
      - MINIO_ROOT_USER=${MINIO_ACCESS_KEY:-minioadmin}
      - MINIO_ROOT_PASSWORD=${MINIO_SECRET_KEY:-minioadmin}
      - TZ=Asia/Shanghai
    expose:
      - "9000"
      - "9001"
    volumes:
      - minio_data:/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - ai-infra-network
    restart: unless-stopped

  # AppHub - 二进制包仓库服务 (DEB/RPM packages)
  apphub:
    build:
      context: ./src/apphub
      dockerfile: Dockerfile
    image: ${PRIVATE_REGISTRY}ai-infra-apphub:${IMAGE_TAG}
    container_name: ai-infra-apphub
    env_file:
      - .env
    ports:
      - "${EXTERNAL_HOST}:${APPHUB_PORT}:80"
    volumes:
      - apphub_logs:/var/log/nginx
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - ai-infra-network
    restart: unless-stopped

  # Nightingale - 监控告警系统
  nightingale:
    build:
      context: ./src/nightingale
      dockerfile: Dockerfile
    image: ${PRIVATE_REGISTRY}ai-infra-nightingale:${IMAGE_TAG}
    container_name: ai-infra-nightingale
    hostname: nightingale
    env_file:
      - .env
    environment:
      GIN_MODE: release
      TZ: Asia/Shanghai
      WAIT_HOSTS: postgres:5432, ai-infra-redis:6379
    ports:
      - "${EXTERNAL_HOST}:${NIGHTINGALE_PORT:-17000}:17000"  # HTTP API
      - "${EXTERNAL_HOST}:${NIGHTINGALE_ALERT_PORT:-19000}:19000"  # Alert engine
    volumes:
      - ./src/nightingale/etc:/app/etc:ro
      - nightingale_data:/app/data
      - nightingale_logs:/app/logs
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:17000/api/v1/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - ai-infra-network
    restart: unless-stopped

volumes:
  postgres_data:
    name: ai-infra-postgres-data
  mysql_data:
    name: ai-infra-mysql-data
  redis_data:
    name: ai-infra-redis-data
  kafka_data:
    name: ai-infra-kafka-data
  kafka_logs:
    name: ai-infra-kafka-logs
  ldap_data:
    name: ai-infra-ldap-data
  ldap_config:
    name: ai-infra-ldap-config
  jupyterhub_data:
    name: ai-infra-jupyterhub-data
  jupyterhub_notebooks:
    name: ai-infra-jupyterhub-notebooks
  nginx_logs:
    name: ai-infra-nginx-logs
  salt_data:
    name: ai-infra-salt-data
  salt_logs:
    name: ai-infra-salt-logs
  salt_keys:
    name: ai-infra-salt-keys
  slurm_master_data:
    name: ai-infra-slurm-master-data
  slurm_master_logs:
    name: ai-infra-slurm-master-logs
  slurm_master_spool:
    name: ai-infra-slurm-master-spool
  slurm_munge_data:
    name: ai-infra-slurm-munge-data
  gitea_data:
    name: ai-infra-gitea-data
  minio_data:
    name: ai-infra-minio-data
  apphub_logs:
    name: ai-infra-apphub-logs
  nightingale_data:
    name: ai-infra-nightingale-data
  nightingale_logs:
    name: ai-infra-nightingale-logs

networks:
  ai-infra-network:
    name: ai-infra-network
    driver: bridge
